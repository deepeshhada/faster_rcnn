{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object Detection - Faster RCNN_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnL1TvO-UQEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import  absolute_import\n",
        "import cupy as cp\n",
        "import os\n",
        "import ipdb\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import resource\n",
        "from collections import namedtuple\n",
        "\n",
        "from utils import array_tool as at\n",
        "from utils.config import opt\n",
        "from utils.vis_tool import Visualizer\n",
        "from model.utils.creator_tool import AnchorTargetCreator, ProposalTargetCreator\n",
        "from data.dataset import Dataset, TestDataset, inverse_normalize\n",
        "from model import FasterRCNNVGG16\n",
        "from utils import array_tool as at\n",
        "from utils.vis_tool import visdom_bbox\n",
        "from utils.eval_tool import eval_detection_voc\n",
        "\n",
        "import matplotlib\n",
        "\n",
        "import torch as t\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data as data_\n",
        "from torchnet.meter import ConfusionMeter, AverageValueMeter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxpuUCymZPkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LossTuple = namedtuple(\n",
        "    'LossTuple',\n",
        "    ['rpn_loc_loss', 'rpn_cls_loss', 'roi_loc_loss', 'roi_cls_loss', 'total_loss']\n",
        ")\n",
        "\n",
        "\n",
        "class FasterRCNNTrainer(nn.Module):\n",
        "    def __init__(self, faster_rcnn):\n",
        "        super(FasterRCNNTrainer, self).__init__()\n",
        "\n",
        "        self.faster_rcnn = faster_rcnn\n",
        "        self.rpn_sigma = opt.rpn_sigma\n",
        "        self.roi_sigma = opt.roi_sigma\n",
        "\n",
        "        # target creator create gt_bbox gt_label etc as training targets. \n",
        "        self.anchor_target_creator = AnchorTargetCreator()\n",
        "        self.proposal_target_creator = ProposalTargetCreator()\n",
        "\n",
        "        self.loc_normalize_mean = faster_rcnn.loc_normalize_mean\n",
        "        self.loc_normalize_std = faster_rcnn.loc_normalize_std\n",
        "\n",
        "        self.optimizer = self.faster_rcnn.get_optimizer()\n",
        "        # visdom wrapper\n",
        "        self.vis = Visualizer(env=opt.env)\n",
        "\n",
        "        # indicators for training status\n",
        "        self.rpn_cm = ConfusionMeter(2)\n",
        "        self.roi_cm = ConfusionMeter(21)\n",
        "        self.meters = {k: AverageValueMeter() for k in LossTuple._fields}  # average loss\n",
        "\n",
        "    def forward(self, imgs, bboxes, labels, scale):\n",
        "        n = bboxes.shape[0]\n",
        "        if n != 1:\n",
        "            raise ValueError('Currently only batch size 1 is supported.')\n",
        "\n",
        "        _, _, H, W = imgs.shape\n",
        "        img_size = (H, W)\n",
        "\n",
        "        features = self.faster_rcnn.extractor(imgs)\n",
        "\n",
        "        rpn_locs, rpn_scores, rois, roi_indices, anchor = \\\n",
        "            self.faster_rcnn.rpn(features, img_size, scale)\n",
        "\n",
        "        bbox = bboxes[0]\n",
        "        label = labels[0]\n",
        "        rpn_score = rpn_scores[0]\n",
        "        rpn_loc = rpn_locs[0]\n",
        "        roi = rois\n",
        "\n",
        "        sample_roi, gt_roi_loc, gt_roi_label = self.proposal_target_creator(\n",
        "            roi,\n",
        "            at.tonumpy(bbox),\n",
        "            at.tonumpy(label),\n",
        "            self.loc_normalize_mean,\n",
        "            self.loc_normalize_std)\n",
        "\n",
        "        sample_roi_index = t.zeros(len(sample_roi))\n",
        "        roi_cls_loc, roi_score = self.faster_rcnn.head(\n",
        "            features,\n",
        "            sample_roi,\n",
        "            sample_roi_index)\n",
        "\n",
        "        gt_rpn_loc, gt_rpn_label = self.anchor_target_creator(\n",
        "            at.tonumpy(bbox),\n",
        "            anchor,\n",
        "            img_size)\n",
        "        gt_rpn_label = at.totensor(gt_rpn_label).long()\n",
        "        gt_rpn_loc = at.totensor(gt_rpn_loc)\n",
        "        rpn_loc_loss = _fast_rcnn_loc_loss(\n",
        "            rpn_loc,\n",
        "            gt_rpn_loc,\n",
        "            gt_rpn_label.data,\n",
        "            self.rpn_sigma)\n",
        "\n",
        "        rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_label.cuda(), ignore_index=-1)\n",
        "        _gt_rpn_label = gt_rpn_label[gt_rpn_label > -1]\n",
        "        _rpn_score = at.tonumpy(rpn_score)[at.tonumpy(gt_rpn_label) > -1]\n",
        "        self.rpn_cm.add(at.totensor(_rpn_score, False), _gt_rpn_label.data.long())\n",
        "\n",
        "        n_sample = roi_cls_loc.shape[0]\n",
        "        roi_cls_loc = roi_cls_loc.view(n_sample, -1, 4)\n",
        "        roi_loc = roi_cls_loc[t.arange(0, n_sample).long().cuda(), \\\n",
        "                              at.totensor(gt_roi_label).long()]\n",
        "        gt_roi_label = at.totensor(gt_roi_label).long()\n",
        "        gt_roi_loc = at.totensor(gt_roi_loc)\n",
        "\n",
        "        roi_loc_loss = _fast_rcnn_loc_loss(\n",
        "            roi_loc.contiguous(),\n",
        "            gt_roi_loc,\n",
        "            gt_roi_label.data,\n",
        "            self.roi_sigma)\n",
        "\n",
        "        roi_cls_loss = nn.CrossEntropyLoss()(roi_score, gt_roi_label.cuda())\n",
        "\n",
        "        self.roi_cm.add(at.totensor(roi_score, False), gt_roi_label.data.long())\n",
        "\n",
        "        losses = [rpn_loc_loss, rpn_cls_loss, roi_loc_loss, roi_cls_loss]\n",
        "        losses = losses + [sum(losses)]\n",
        "\n",
        "        return LossTuple(*losses)\n",
        "\n",
        "    def train_step(self, imgs, bboxes, labels, scale):\n",
        "        self.optimizer.zero_grad()\n",
        "        losses = self.forward(imgs, bboxes, labels, scale)\n",
        "        losses.total_loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.update_meters(losses)\n",
        "        return losses\n",
        "\n",
        "    def save(self, save_optimizer=False, save_path=None, **kwargs):\n",
        "        save_dict = dict()\n",
        "\n",
        "        save_dict['model'] = self.faster_rcnn.state_dict()\n",
        "        save_dict['config'] = opt._state_dict()\n",
        "        save_dict['other_info'] = kwargs\n",
        "        save_dict['vis_info'] = self.vis.state_dict()\n",
        "\n",
        "        if save_optimizer:\n",
        "            save_dict['optimizer'] = self.optimizer.state_dict()\n",
        "\n",
        "        if save_path is None:\n",
        "            timestr = time.strftime('%m%d%H%M')\n",
        "            save_path = 'checkpoints/fasterrcnn_%s' % timestr\n",
        "            for k_, v_ in kwargs.items():\n",
        "                save_path += '_%s' % v_\n",
        "\n",
        "        save_dir = os.path.dirname(save_path)\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        t.save(save_dict, save_path)\n",
        "        self.vis.save([self.vis.env])\n",
        "        return save_path\n",
        "\n",
        "    def load(self, path, load_optimizer=True, parse_opt=False, ):\n",
        "        state_dict = t.load(path)\n",
        "        if 'model' in state_dict:\n",
        "            self.faster_rcnn.load_state_dict(state_dict['model'])\n",
        "        else:\n",
        "            self.faster_rcnn.load_state_dict(state_dict)\n",
        "            return self\n",
        "        if parse_opt:\n",
        "            opt._parse(state_dict['config'])\n",
        "        if 'optimizer' in state_dict and load_optimizer:\n",
        "            self.optimizer.load_state_dict(state_dict['optimizer'])\n",
        "        return self\n",
        "\n",
        "    def update_meters(self, losses):\n",
        "        loss_d = {k: at.scalar(v) for k, v in losses._asdict().items()}\n",
        "        for key, meter in self.meters.items():\n",
        "            meter.add(loss_d[key])\n",
        "\n",
        "    def reset_meters(self):\n",
        "        for key, meter in self.meters.items():\n",
        "            meter.reset()\n",
        "        self.roi_cm.reset()\n",
        "        self.rpn_cm.reset()\n",
        "\n",
        "    def get_meter_data(self):\n",
        "        return {k: v.value()[0] for k, v in self.meters.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_5bJDrEZ3vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _smooth_l1_loss(x, t, in_weight, sigma):\n",
        "    sigma2 = sigma ** 2\n",
        "    diff = in_weight * (x - t)\n",
        "    abs_diff = diff.abs()\n",
        "    flag = (abs_diff.data < (1. / sigma2)).float()\n",
        "    y = (flag * (sigma2 / 2.) * (diff ** 2) +\n",
        "         (1 - flag) * (abs_diff - 0.5 / sigma2))\n",
        "    return y.sum()\n",
        "\n",
        "\n",
        "def _fast_rcnn_loc_loss(pred_loc, gt_loc, gt_label, sigma):\n",
        "    in_weight = t.zeros(gt_loc.shape).cuda()\n",
        "    in_weight[(gt_label > 0).view(-1, 1).expand_as(in_weight).cuda()] = 1\n",
        "    loc_loss = _smooth_l1_loss(pred_loc, gt_loc, in_weight.detach(), sigma)\n",
        "    loc_loss /= ((gt_label >= 0).sum().float()) # ignore gt_label==-1 for rpn_loss\n",
        "    return loc_loss\n",
        "\n",
        "\n",
        "def eval(dataloader, faster_rcnn, test_num=10000):\n",
        "    pred_bboxes, pred_labels, pred_scores = list(), list(), list()\n",
        "    gt_bboxes, gt_labels, gt_difficults = list(), list(), list()\n",
        "    for ii, (imgs, sizes, gt_bboxes_, gt_labels_, gt_difficults_) in tqdm(enumerate(dataloader)):\n",
        "        sizes = [sizes[0][0].item(), sizes[1][0].item()]\n",
        "        pred_bboxes_, pred_labels_, pred_scores_ = faster_rcnn.predict(imgs, [sizes])\n",
        "        gt_bboxes += list(gt_bboxes_.numpy())\n",
        "        gt_labels += list(gt_labels_.numpy())\n",
        "        gt_difficults += list(gt_difficults_.numpy())\n",
        "        pred_bboxes += pred_bboxes_\n",
        "        pred_labels += pred_labels_\n",
        "        pred_scores += pred_scores_\n",
        "        if ii == test_num: break\n",
        "\n",
        "    result = eval_detection_voc(\n",
        "        pred_bboxes, pred_labels, pred_scores,\n",
        "        gt_bboxes, gt_labels, gt_difficults,\n",
        "        use_07_metric=True)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPTriMvNZ45S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
        "resource.setrlimit(resource.RLIMIT_NOFILE, (20480, rlimit[1]))\n",
        "matplotlib.use('agg')\n",
        "\n",
        "\n",
        "def train(**kwargs):\n",
        "    opt._parse(kwargs)\n",
        "\n",
        "    dataset = Dataset(opt)\n",
        "    dataloader = data_.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "        num_workers=opt.num_workers\n",
        "    )\n",
        "\n",
        "    testset = TestDataset(opt)\n",
        "    test_dataloader = data_.DataLoader(\n",
        "        testset,\n",
        "        batch_size=1,\n",
        "        num_workers=opt.test_num_workers,\n",
        "        shuffle=False, \\\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    faster_rcnn = FasterRCNNVGG16()\n",
        "    trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
        "    if opt.load_path:\n",
        "        trainer.load(opt.load_path)\n",
        "        print('Loaded pretrained model from %s' % opt.load_path)\n",
        "    trainer.vis.text(dataset.db.label_names, win='labels')\n",
        "\n",
        "    best_map = 0\n",
        "    lr_ = opt.lr\n",
        "    for epoch in range(opt.epoch):\n",
        "        trainer.reset_meters()\n",
        "        for ii, (img, bbox_, label_, scale) in tqdm(enumerate(dataloader)):\n",
        "            scale = at.scalar(scale)\n",
        "            img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
        "            trainer.train_step(img, bbox, label, scale)\n",
        "\n",
        "            if (ii + 1) % opt.plot_every == 0:\n",
        "                if os.path.exists(opt.debug_file):\n",
        "                    ipdb.set_trace()\n",
        "                trainer.vis.plot_many(trainer.get_meter_data())\n",
        "                ori_img_ = inverse_normalize(at.tonumpy(img[0]))\n",
        "                gt_img = visdom_bbox(ori_img_,\n",
        "                                     at.tonumpy(bbox_[0]),\n",
        "                                     at.tonumpy(label_[0]))\n",
        "                trainer.vis.img('gt_img', gt_img)\n",
        "                _bboxes, _labels, _scores = trainer.faster_rcnn.predict([ori_img_], visualize=True)\n",
        "                pred_img = visdom_bbox(ori_img_,\n",
        "                                       at.tonumpy(_bboxes[0]),\n",
        "                                       at.tonumpy(_labels[0]).reshape(-1),\n",
        "                                       at.tonumpy(_scores[0]))\n",
        "                trainer.vis.img('pred_img', pred_img)\n",
        "                trainer.vis.text(str(trainer.rpn_cm.value().tolist()), win='rpn_cm')\n",
        "                trainer.vis.img('roi_cm', at.totensor(trainer.roi_cm.conf, False).float())\n",
        "        eval_result = eval(test_dataloader, faster_rcnn, test_num=opt.test_num)\n",
        "        trainer.vis.plot('test_map', eval_result['map'])\n",
        "        lr_ = trainer.faster_rcnn.optimizer.param_groups[0]['lr']\n",
        "        log_info = 'lr:{}, map:{},loss:{}'.format(str(lr_),\n",
        "                                                  str(eval_result['map']),\n",
        "                                                  str(trainer.get_meter_data()))\n",
        "        trainer.vis.log(log_info)\n",
        "\n",
        "        if eval_result['map'] > best_map:\n",
        "            best_map = eval_result['map']\n",
        "            best_path = trainer.save(best_map=best_map)\n",
        "        if epoch == 9:\n",
        "            trainer.load(best_path)\n",
        "            trainer.faster_rcnn.scale_lr(opt.lr_decay)\n",
        "            lr_ = lr_ * opt.lr_decay\n",
        "\n",
        "        if epoch == 13: \n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0gXT4V3bcGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(opt)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}